{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport cv2\n\n%matplotlib inline\nfrom matplotlib import pyplot as plt\n\nnp.random.seed(42)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T12:04:36.478001Z","iopub.execute_input":"2022-03-04T12:04:36.478432Z","iopub.status.idle":"2022-03-04T12:04:36.542524Z","shell.execute_reply.started":"2022-03-04T12:04:36.478297Z","shell.execute_reply":"2022-03-04T12:04:36.5418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Routine to fix \ndef fixColor(image):\n    return(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","metadata":{"execution":{"iopub.status.busy":"2022-03-04T12:04:39.114143Z","iopub.execute_input":"2022-03-04T12:04:39.114879Z","iopub.status.idle":"2022-03-04T12:04:39.119159Z","shell.execute_reply.started":"2022-03-04T12:04:39.114834Z","shell.execute_reply":"2022-03-04T12:04:39.118102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Take a look at the input video\nfrom IPython.display import Video\n#Video(\"images/overpass.mp4\", embed=True)\n\n#Replace with your own video","metadata":{"execution":{"iopub.status.busy":"2022-03-04T12:04:43.337096Z","iopub.execute_input":"2022-03-04T12:04:43.337373Z","iopub.status.idle":"2022-03-04T12:04:43.341043Z","shell.execute_reply.started":"2022-03-04T12:04:43.337323Z","shell.execute_reply":"2022-03-04T12:04:43.34013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"video_stream = cv2.VideoCapture('../input/mindnew/IMG_0425.MOV')\n\n# Randomly select 30 frames\n\nframeIds = video_stream.get(cv2.CAP_PROP_FRAME_COUNT) * np.random.uniform(size=30)\n\n# Store selected frames in an array\nframes = []\nfor fid in frameIds:\n    video_stream.set(cv2.CAP_PROP_POS_FRAMES, fid)\n    ret, frame = video_stream.read()\n    frames.append(frame)\n    \nvideo_stream.release()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-04T11:11:08.429013Z","iopub.execute_input":"2022-03-04T11:11:08.430149Z","iopub.status.idle":"2022-03-04T11:11:33.180031Z","shell.execute_reply.started":"2022-03-04T11:11:08.430112Z","shell.execute_reply":"2022-03-04T11:11:33.179277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the median along the time axis\nmedianFrame = np.median(frames, axis=0).astype(dtype=np.uint8)\nplt.imshow(fixColor(medianFrame))","metadata":{"execution":{"iopub.status.busy":"2022-03-04T11:11:33.181152Z","iopub.execute_input":"2022-03-04T11:11:33.181419Z","iopub.status.idle":"2022-03-04T11:11:43.426732Z","shell.execute_reply.started":"2022-03-04T11:11:33.181386Z","shell.execute_reply":"2022-03-04T11:11:43.424411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the average along the time axis\navgFrame = np.average(frames, axis=0).astype(dtype=np.uint8)\nplt.imshow(fixColor(avgFrame))","metadata":{"execution":{"iopub.status.busy":"2022-03-04T11:11:43.428414Z","iopub.execute_input":"2022-03-04T11:11:43.429654Z","iopub.status.idle":"2022-03-04T11:11:44.662599Z","shell.execute_reply.started":"2022-03-04T11:11:43.429612Z","shell.execute_reply":"2022-03-04T11:11:44.6606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_frame=frames[0]\nplt.imshow(fixColor(sample_frame))","metadata":{"execution":{"iopub.status.busy":"2022-03-04T11:11:44.663948Z","iopub.status.idle":"2022-03-04T11:11:44.664552Z","shell.execute_reply.started":"2022-03-04T11:11:44.66431Z","shell.execute_reply":"2022-03-04T11:11:44.664344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For identifying moving objects it is better to work with grayscale images. We will convert both the median image and sample image to grayscale","metadata":{}},{"cell_type":"code","source":"grayMedianFrame = cv2.cvtColor(medianFrame, cv2.COLOR_BGR2GRAY)\nplt.imshow(fixColor(grayMedianFrame))","metadata":{"execution":{"iopub.status.busy":"2022-03-04T11:11:44.665791Z","iopub.status.idle":"2022-03-04T11:11:44.666385Z","shell.execute_reply.started":"2022-03-04T11:11:44.666138Z","shell.execute_reply":"2022-03-04T11:11:44.666163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"graySample=cv2.cvtColor(sample_frame, cv2.COLOR_BGR2GRAY)\nplt.imshow(fixColor(graySample))","metadata":{"execution":{"iopub.status.busy":"2022-03-04T11:11:44.667459Z","iopub.status.idle":"2022-03-04T11:11:44.668019Z","shell.execute_reply.started":"2022-03-04T11:11:44.667787Z","shell.execute_reply":"2022-03-04T11:11:44.667811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Remove background\nRemove the background from our sample. We can now see a ghost image with cars and background removed.","metadata":{}},{"cell_type":"code","source":"dframe = cv2.absdiff(graySample, grayMedianFrame)\nplt.imshow(fixColor(dframe))","metadata":{"execution":{"iopub.status.busy":"2022-03-04T11:11:44.669083Z","iopub.status.idle":"2022-03-04T11:11:44.669644Z","shell.execute_reply.started":"2022-03-04T11:11:44.669416Z","shell.execute_reply":"2022-03-04T11:11:44.66944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Blurring\n\nWe will run Gaussian blurring to reduce noise and enable easier identification of edges","metadata":{}},{"cell_type":"code","source":"blurred = cv2.GaussianBlur(dframe, (11,11), 0)\nplt.imshow(fixColor(blurred))","metadata":{"execution":{"iopub.status.busy":"2022-03-04T11:11:44.670688Z","iopub.status.idle":"2022-03-04T11:11:44.67125Z","shell.execute_reply.started":"2022-03-04T11:11:44.67101Z","shell.execute_reply":"2022-03-04T11:11:44.671043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h,w= np.shape(blurred)\nfor px in range(0,h):\n    for py in range(0,w):\n         current_color = blurred[px][py]\n         if(current_color<10):\n            blurred[px][py]=0\n            \n         ","metadata":{"execution":{"iopub.status.busy":"2022-03-04T11:11:44.672464Z","iopub.status.idle":"2022-03-04T11:11:44.673093Z","shell.execute_reply.started":"2022-03-04T11:11:44.672854Z","shell.execute_reply":"2022-03-04T11:11:44.672878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Thresholding\n\nWe will now run a threshold to clear bring out the objects left here. We will use OTSU thresholding which automatically figure out the correct thresold levels.","metadata":{}},{"cell_type":"code","source":"plt.imshow(blurred)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T11:11:44.674158Z","iopub.status.idle":"2022-03-04T11:11:44.674724Z","shell.execute_reply.started":"2022-03-04T11:11:44.674495Z","shell.execute_reply":"2022-03-04T11:11:44.674519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Contour and Bounding Boxes\n\nWe will create contours using the thresholded pictures","metadata":{}},{"cell_type":"code","source":"(cnts, _) = cv2.findContours(tframe.copy(), cv2.RETR_EXTERNAL, \n                             cv2 .CHAIN_APPROX_SIMPLE)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T11:11:44.675776Z","iopub.status.idle":"2022-03-04T11:11:44.676321Z","shell.execute_reply.started":"2022-03-04T11:11:44.6761Z","shell.execute_reply":"2022-03-04T11:11:44.676123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will now create bounding boxes for the contours identified and show them on our sample images. We will disregard items like moving clouds in the top of our picture","metadata":{}},{"cell_type":"code","source":"for cnt in cnts:\n    x,y,w,h = cv2.boundingRect(cnt)\n    if y > 200:  #Disregard item that are the top of the picture\n        cv2.rectangle(sample_frame,(x,y),(x+w,y+h),(0,255,0),2)\n\nplt.imshow(fixColor(sample_frame))","metadata":{"execution":{"iopub.status.busy":"2022-03-04T11:11:44.677407Z","iopub.status.idle":"2022-03-04T11:11:44.67796Z","shell.execute_reply.started":"2022-03-04T11:11:44.677729Z","shell.execute_reply":"2022-03-04T11:11:44.677753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vid = cv2.VideoCapture(\"../input/mindnew/IMG_0425.MOV\") \n\ncurrentframe = 0\nwhile(True): \n      \n    ret,frame = vid.read() \n  \n    if ret: \n        name = 'frame' + str(currentframe) + '.jpg' \n        cv2.imwrite(name, frame) \n        currentframe += 1\n    else: \n        print(\"--> Frames Created <--\")\n        break","metadata":{"execution":{"iopub.status.busy":"2022-03-04T11:11:44.679051Z","iopub.status.idle":"2022-03-04T11:11:44.679622Z","shell.execute_reply.started":"2022-03-04T11:11:44.679389Z","shell.execute_reply":"2022-03-04T11:11:44.679413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h,w= np.shape(blurred)\nfor px in range(0,h):\n    for py in range(0,w):\n         current_color = blurred[px][py]\n         if(current_color<10):\n            blurred[px][py]=0\n            ","metadata":{"execution":{"iopub.status.busy":"2022-03-04T11:11:44.68067Z","iopub.status.idle":"2022-03-04T11:11:44.681236Z","shell.execute_reply.started":"2022-03-04T11:11:44.68099Z","shell.execute_reply":"2022-03-04T11:11:44.681014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install Image","metadata":{"execution":{"iopub.status.busy":"2022-03-04T11:11:44.682288Z","iopub.status.idle":"2022-03-04T11:11:44.682856Z","shell.execute_reply.started":"2022-03-04T11:11:44.682623Z","shell.execute_reply":"2022-03-04T11:11:44.682648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport glob\n#for filename in glob.glob('*.jpg'):\nimg = Image.open('../input/image1/Sample2.jpg')\nheight,width= img.size\nfor y in range(width):\n    for x in range(height):\n        current_color = img.getpixel( (x,y) )\n        a,b,c=current_color\n        new_color=(255,255,255)\n        new_color1=(0,0,0)\n        if(a>120 or b>120 or c>120):\n            img.putpixel( (x,y), new_color)\n        else:\n            img.putpixel( (x,y), new_color1)\nplt.imshow(img)    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-04T12:08:23.113739Z","iopub.execute_input":"2022-03-04T12:08:23.114044Z","iopub.status.idle":"2022-03-04T12:08:24.058826Z","shell.execute_reply.started":"2022-03-04T12:08:23.114012Z","shell.execute_reply":"2022-03-04T12:08:24.058185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pytesseract\ntext=pytesseract.image_to_string(img)\nprint(\"Text in Image :-\")\nprint(\"----------------\")\nprint(text)\n\nprint(\"Original Image :-\")\nprint(\"----------------\")\nprint(plt.imshow(img))","metadata":{"execution":{"iopub.status.busy":"2022-03-04T11:19:26.203697Z","iopub.execute_input":"2022-03-04T11:19:26.204089Z","iopub.status.idle":"2022-03-04T11:19:26.773912Z","shell.execute_reply.started":"2022-03-04T11:19:26.204049Z","shell.execute_reply":"2022-03-04T11:19:26.773136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"height, width, layers = frames[0].shape\nsize = (width,height)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T11:11:44.685548Z","iopub.status.idle":"2022-03-04T11:11:44.686099Z","shell.execute_reply.started":"2022-03-04T11:11:44.685863Z","shell.execute_reply":"2022-03-04T11:11:44.685887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"out = cv2.VideoWriter('Out-Put.avi',cv2.VideoWriter_fourcc(*'DIVX'), 30, size)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T11:11:44.687157Z","iopub.status.idle":"2022-03-04T11:11:44.687726Z","shell.execute_reply.started":"2022-03-04T11:11:44.687494Z","shell.execute_reply":"2022-03-04T11:11:44.687518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nimg_array = []\nfor filename in glob.glob('*.jpg'):\n    img = cv2.imread(filename)\n    height, width, layers = img.shape\n    size = (width,height)\n    \n    gframe = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n   \n    dframe = cv2.absdiff(gframe, grayMedianFrame)\n  \n    blurred = cv2.GaussianBlur(dframe, (11, 11), 0)\n   \n    ret, tframe= cv2.threshold(blurred,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n  \n    (cnts, _) = cv2.findContours(tframe.copy(),cv2.RETR_EXTERNAL, cv2 .CHAIN_APPROX_SIMPLE)\n\n    for cnt in cnts:\n        x,y,w,h = cv2.boundingRect(cnt)\n        if y > 200:\n            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n    \n    img_array.append(frame)\n    \nfor i in range(len(img_array)):\n    out.write(img_array[i])\nout.release()\n\nprint(\"Output Video Created As Out-Put.avi\")","metadata":{"execution":{"iopub.status.busy":"2022-03-04T11:11:44.688791Z","iopub.status.idle":"2022-03-04T11:11:44.689363Z","shell.execute_reply.started":"2022-03-04T11:11:44.689121Z","shell.execute_reply":"2022-03-04T11:11:44.689144Z"},"trusted":true},"execution_count":null,"outputs":[]}]}